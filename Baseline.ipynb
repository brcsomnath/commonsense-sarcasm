{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from localutils import *\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertModel, BertTokenizer, DistilBertTokenizer, RobertaTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import RobertaForSequenceClassification, BertForSequenceClassification, AdamW, BertConfig, DistilBertForSequenceClassification, DistilBertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'news_headline' : {\n",
    "        'dataset_path': 'data/NewsHeadline_comet_autocomplete.jsonl',\n",
    "        'model_name': 'distilbert',\n",
    "        'model_save_point': 'kaggle-news',\n",
    "        'epochs': 5,\n",
    "        'test_size': 0.5\n",
    "    },\n",
    "    \n",
    "    'semeval' : {\n",
    "        'dataset_path': 'data/FullSEMEVAL_comet.jsonl', #'data/SemEval_comet_autocomplete.jsonl',\n",
    "        'model_name': 'distilbert',\n",
    "        'model_save_point': 'semeval',\n",
    "        'epochs': 10,\n",
    "        'test_size': 0.2\n",
    "    },\n",
    "    \n",
    "    'figlang' : {\n",
    "        'dataset_path': 'data/FigLang_comet_autocomplete.jsonl',\n",
    "        'model_name': 'distilbert',\n",
    "        'model_save_point': 'figlang',\n",
    "        'epochs': 10,\n",
    "        'test_size': 0.2\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs['semeval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = config['dataset_path']\n",
    "\n",
    "def load_dataset(filename = PATH):\n",
    "    dataset = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            entry = {}\n",
    "            \n",
    "            line = line.strip()\n",
    "            d = json.loads(line)\n",
    "            \n",
    "            entry['sentence'] = d['sentence']\n",
    "            entry['label'] = int(d['label'])\n",
    "            entry['support'] = []\n",
    "            for k in d['common_sense'].keys():\n",
    "                if k == 'xWant' or k == 'xEffect':\n",
    "                    entry['support'].append(d['common_sense'][k][0] if d['common_sense'][k][0] != 'none' else d['common_sense'][k][1])\n",
    "\n",
    "            dataset.append(entry)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "\n",
    "if model_name == \"distilbert\":\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "elif model_name == \"bert\":\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "elif model_name == \"roberta\":\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_all(sentences):\n",
    "    input_ids = []\n",
    "    for data in sentences:\n",
    "        input_ids.append(tokenizer.encode(data, add_special_tokens=True))\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn(input_ids):\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        attention_masks.append(att_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    all_data = []\n",
    "    \n",
    "    for data in tqdm(dataset):\n",
    "        input_ids = []\n",
    "        \n",
    "        input_ids.append(tokenizer.encode(data['sentence'].lower()))\n",
    "        \n",
    "        for s in data['support']:\n",
    "            input_ids.append(tokenizer.encode(s.lower()))\n",
    "            \n",
    "        input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "        attn_mask = torch.tensor(get_attn(input_ids))\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        \n",
    "        entry = {}\n",
    "        entry['raw_sentence'] = data['sentence'] + \" [SUPPORT]: \" + \" [SEP] \".join(data['support'])\n",
    "        entry['sentence'] = input_ids[0]\n",
    "        entry['sentence_mask'] = attn_mask[0]\n",
    "        \n",
    "        entry['support'] = input_ids[1:]\n",
    "        entry['support_mask'] = attn_mask[1:]\n",
    "        \n",
    "        all_data.append((entry, data['label']))\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3834/3834 [00:03<00:00, 1212.76it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_list = create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset = train_test_split(dataset_list, random_state=2018, test_size=config['test_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset():\n",
    "    with open('model/trainset-' + config['model_save_point'] +'.data', 'wb') as f:\n",
    "        pickle.dump(trainset, f)\n",
    "\n",
    "    with open('model/validationset-' + config['model_save_point'] + '.data', 'wb') as f:\n",
    "        pickle.dump(validationset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(validationset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Our Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "\n",
    "if model_name == \"distilbert\":\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "                                            \"distilbert-base-uncased\",\n",
    "                                            num_labels = 2, \n",
    "                                            output_attentions = False, \n",
    "                                            output_hidden_states = True, \n",
    "                                        )\n",
    "elif model_name == \"roberta\":\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "                                            \"roberta-base\",\n",
    "                                            num_labels = 2, \n",
    "                                            output_attentions = True, \n",
    "                                            output_hidden_states = False, \n",
    "                                        )\n",
    "elif model_name == \"roberta\":\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "                                            \"bert-base-uncased\",\n",
    "                                            num_labels = 2, \n",
    "                                            output_attentions = False, \n",
    "                                            output_hidden_states = False, \n",
    "                                        )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "total_steps = len(train_loader) * config['epochs']\n",
    "    \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, (batch, labels) in enumerate(train_loader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n",
    "\n",
    "        b_input_ids = batch['sentence'].to(device)\n",
    "        b_input_mask = batch['sentence_mask'].to(device)\n",
    "        b_labels = labels.to(device)\n",
    "        model.zero_grad()        \n",
    "        \n",
    "        outputs = model(b_input_ids, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "                \n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)            \n",
    "    \n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    for batch, b_labels in test_loader:\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(batch['sentence'].to(device), \n",
    "                            attention_mask=batch['sentence_mask'].to(device))\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        prediction = list(np.argmax(logits, axis=1).flatten())\n",
    "        all_predictions.extend(prediction)\n",
    "        all_labels.extend(label_ids.flatten())\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    acc = eval_accuracy/nb_eval_steps\n",
    "    print(\"  Accuracy: {0:.2f}\".format(acc))\n",
    "    \n",
    "    \n",
    "    matrix = confusion_matrix(all_predictions, all_labels)\n",
    "\n",
    "    tp = matrix[0][0]\n",
    "    fp = matrix[0][1]\n",
    "    fn = matrix[1][0]\n",
    "    tn = matrix[1][1]\n",
    "    \n",
    "    print(\"  Sarcastic Precision: {0:.4f}\".format(tp/ (tp + fp)))\n",
    "    print(\"  Sarcastic F1-score: {0:.4f}\".format(2*tp / (2*tp + fn + fp)))\n",
    "    print(\"  Sarcastic Recall: {0:.4f}\".format(tp / (tp + fn))) \n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"  Non-sarcastic Precision: {0:.4f}\".format(tn / (tn + fn)))\n",
    "    print(\"  Non-Sarcastic F1-score: {0:.4f}\".format(2*tn / (2*tn + fn + fp)))\n",
    "    print(\"  Non-sarcasm Recall: {0:.4f}\".format(tn / (tn + fp)))\n",
    "    \n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filename = 'model/distilbert-'+ config['model_save_point'] +'.pb'):\n",
    "    print('Saving model...')\n",
    "    torch.save(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:02.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:06.\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Sarcastic Precision: 0.6677\n",
      "  Sarcastic F1-score: 0.6152\n",
      "  Sarcastic Recall: 0.5703\n",
      "\n",
      "  Non-sarcastic Precision: 0.6241\n",
      "  Non-Sarcastic F1-score: 0.6667\n",
      "  Non-sarcasm Recall: 0.7154\n",
      "  Validation took: 0:00:00\n",
      "Saving model...\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Sarcastic Precision: 0.6697\n",
      "  Sarcastic F1-score: 0.7099\n",
      "  Sarcastic Recall: 0.7552\n",
      "\n",
      "  Non-sarcastic Precision: 0.7186\n",
      "  Non-Sarcastic F1-score: 0.6695\n",
      "  Non-sarcasm Recall: 0.6266\n",
      "  Validation took: 0:00:00\n",
      "Saving model...\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Sarcastic Precision: 0.6983\n",
      "  Sarcastic F1-score: 0.6739\n",
      "  Sarcastic Recall: 0.6510\n",
      "\n",
      "  Non-sarcastic Precision: 0.6724\n",
      "  Non-Sarcastic F1-score: 0.6944\n",
      "  Non-sarcasm Recall: 0.7180\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Sarcastic Precision: 0.7578\n",
      "  Sarcastic F1-score: 0.5568\n",
      "  Sarcastic Recall: 0.4401\n",
      "\n",
      "  Non-sarcastic Precision: 0.6048\n",
      "  Non-Sarcastic F1-score: 0.7098\n",
      "  Non-sarcasm Recall: 0.8590\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Sarcastic Precision: 0.6802\n",
      "  Sarcastic F1-score: 0.6667\n",
      "  Sarcastic Recall: 0.6536\n",
      "\n",
      "  Non-sarcastic Precision: 0.6658\n",
      "  Non-Sarcastic F1-score: 0.6786\n",
      "  Non-sarcasm Recall: 0.6919\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Sarcastic Precision: 0.6427\n",
      "  Sarcastic F1-score: 0.7187\n",
      "  Sarcastic Recall: 0.8151\n",
      "\n",
      "  Non-sarcastic Precision: 0.7464\n",
      "  Non-Sarcastic F1-score: 0.6305\n",
      "  Non-sarcasm Recall: 0.5457\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Sarcastic Precision: 0.6881\n",
      "  Sarcastic F1-score: 0.6917\n",
      "  Sarcastic Recall: 0.6953\n",
      "\n",
      "  Non-sarcastic Precision: 0.6913\n",
      "  Non-Sarcastic F1-score: 0.6877\n",
      "  Non-sarcasm Recall: 0.6841\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Sarcastic Precision: 0.6772\n",
      "  Sarcastic F1-score: 0.6745\n",
      "  Sarcastic Recall: 0.6719\n",
      "\n",
      "  Non-sarcastic Precision: 0.6736\n",
      "  Non-Sarcastic F1-score: 0.6762\n",
      "  Non-sarcasm Recall: 0.6789\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:03.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Sarcastic Precision: 0.6781\n",
      "  Sarcastic F1-score: 0.6737\n",
      "  Sarcastic Recall: 0.6693\n",
      "\n",
      "  Non-sarcastic Precision: 0.6727\n",
      "  Non-Sarcastic F1-score: 0.6770\n",
      "  Non-sarcasm Recall: 0.6815\n",
      "  Validation took: 0:00:00\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    192.    Elapsed: 0:00:01.\n",
      "  Batch    80  of    192.    Elapsed: 0:00:02.\n",
      "  Batch   120  of    192.    Elapsed: 0:00:04.\n",
      "  Batch   160  of    192.    Elapsed: 0:00:05.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:00:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Sarcastic Precision: 0.6803\n",
      "  Sarcastic F1-score: 0.6640\n",
      "  Sarcastic Recall: 0.6484\n",
      "\n",
      "  Non-sarcastic Precision: 0.6633\n",
      "  Non-Sarcastic F1-score: 0.6786\n",
      "  Non-sarcasm Recall: 0.6945\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch_i in range(0, config['epochs']):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, config['epochs']))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    train()\n",
    "    acc = test()\n",
    "    if best_val_acc < acc:\n",
    "        best_val_acc = acc\n",
    "        save_model()\n",
    "    \n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
